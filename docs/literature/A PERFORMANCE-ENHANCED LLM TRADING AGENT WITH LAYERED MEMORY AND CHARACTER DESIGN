文獻導讀
Yu et al. (2023)

FINMEM: A Performance-Enhanced LLM Trading Agent with Layered Memory and Character Design
arXiv:2311.13743v2

1. 研究背景與動機

金融市場中的資訊龐雜、形式多元，包括：

即時新聞

公司季報與年報

歷史價格序列

金融代理人需要同時處理不同時間敏感度的信息。但傳統 DRL-based 交易代理人存在如下問題：

缺乏可解釋性，決策來源不透明。

無法有效同時處理價格訊號與文本資訊。

無法在短期訓練資料下收斂。

缺乏記憶機制，無法累積交易經驗。

FINMEM 提出一個新的 LLM-based 交易代理架構，使系統能像人類交易員一樣：

有長期與短期記憶

能解讀文本與市場數據

能依據市場狀態寫出可讀的理由

能依據設定調整風險傾向

2. 研究目的

FINMEM 的目標是建構：

強化 LLM 的金融決策能力

具備可解釋性的交易代理

具有類人記憶結構（working + long-term memory）

能整合多來源資料（news, 10-Q, 10-K, price）

可依市場狀態自動調整風險偏好（risk-seeking / risk-averse）

3. 系統架構概述

FINMEM 由三個核心模組組成：

3.1 Profiling Module（角色設定模組）

為代理注入「專業背景」

注入該股票的歷史資料

三類風險偏好：

Risk-seeking

Risk-averse

Self-adaptive（依報酬狀況自動切換）

Profiling 決定代理如何解讀市場事件。

3.2 Memory Module（記憶模組）

模擬人類交易者的 working memory 與 long-term memory：

Working Memory（短期工作記憶）

具備三項操作：

Summarization：提取新聞、報告、文件之投資訊息

Observation：分析市場價格動能

Reflection：整合記憶與價格訊號產生決策理由

Layered Long-Term Memory（分層長期記憶）

長期記憶依資訊的「時效性」分三層：

層級	資料類型	retention（記憶保留）
Shallow	每日新聞	短
Intermediate	季報 10-Q	中
Deep	年報 10-K、延伸反思	長

每筆記憶以三項指標排序：

Recency（新鮮度）

Relevance（語義相關度，使用文本 embedding）

Importance（重要性，含 decay）

決策時從各層取 Top-K 記憶輸入 working memory。

3.3 Decision-Making Module（決策模組）

輸入：

Top-K long-term memories

Working memory summary

Momentum / 過去 M 天累積報酬

Profiling 角色設定

輸出：

Buy / Sell / Hold

理由（自然語言）

使用到的記憶 ID

FINMEM 的決策過程具有明確可檢視性。

4. 實驗與資料
資料來源

Daily price（Yahoo Finance）

Alpaca News API（Benzinga）

SEC 10-Q（季度報）

SEC 10-K（年報）

標的股票

TSLA, NFLX, AMZN, MSFT, COIN

比較模型

PPO, DQN, A2C（DRL agents）

FinGPT

General-purpose Generative Agents

Buy & Hold baseline

5. 實驗結果
5.1 整體績效

FINMEM 在所有股票上：

累積報酬最高

Sharpe ratio 最佳

最大回撤最低

波動度最低或中等

特別是 TSLA、NFLX、MSFT 呈現數據上明顯優勢。

5.2 訓練資料需求

FINMEM 僅需 6–12 個月資料 即可穩定運作。
DRL agent 則需要 至少 10 年資料 才能收斂。

這顯示 LLM-based agents 的強大泛化能力。

5.3 Memory 機制的重要性

Top-K 設定對績效影響明顯：

K = 5 表現最佳

K 過低會遺漏資訊

K 過高會混入噪音

5.4 Character（角色）對績效影響

Risk profiles：

Self-adaptive → 多數股票最佳

Risk-seeking → 適合強勢股（MSFT）

Risk-averse → 謹慎但報酬較低

Profiling 模組能實際調整代理行為。

6. 研究貢獻

提出具備人類式記憶機制（working + layered memory）的 LLM 交易代理架構

處理文本 + 價格資料的整合能力大幅優於 DRL、FinGPT

僅需短期資料即可得到高績效

能自動調整風險傾向應對市場波動

提供自然語言理由，具可解釋性

7. 限制與未來工作

限制：

context length 限制仍存在

記憶排序依賴 embedding similarity

訓練成本高（LLM token usage）

未來方向：

搭配金融專用 LLM

研究 multi-agent trading

設計更深度的時序記憶結構

擴展至 portfolio optimization

8. 與本系統的適用性（L2 層）

FINMEM 論文提供：

8.1 LLM 代理人 architecture 的直接參考

包含：

memory structure

profiling（角色設定）

decision module prompt 架構

非常適合作為 L2「決策代理」設計的理論依據。

8.2 完全對應「事件 → 記憶 → 推理 → 交易行為」流程

你的 L2 是語義推理決策層，这篇提供一個完整範本：

語義摘要輸入

多層記憶整合

LLM reasoning

產生 Buy/Sell/Hold

8.3 明確支持使用 LLM 做二階決策 (meta-reasoning)

FINMEM 的 working memory + reflection 機制正是你 L2 層設計所需的「語義推論 + decision refinement」。

8.4 支持 LLM 能補足 DRL 缺點

可在論文的 motivation 段落引用。
